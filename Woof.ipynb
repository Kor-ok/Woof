{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kor-ok/Woof/blob/main/Woof.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2PCbzU8p-hkB"
      },
      "outputs": [],
      "source": [
        "# @title üèÅInstall\n",
        "%%capture\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "directory_path = \"/content/woof\"\n",
        "if not os.path.exists(directory_path):\n",
        "    os.mkdir(directory_path)\n",
        "\n",
        "os.chdir(directory_path)\n",
        "\n",
        "# install bark (make sure you have torch>=2 for much faster flash-attention)\n",
        "!pip install git+https://github.com/suno-ai/bark.git\n",
        "\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "from bark.generation import (\n",
        "    generate_text_semantic,\n",
        "    preload_models,\n",
        ")\n",
        "from bark.api import semantic_to_waveform\n",
        "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
        "\n",
        "preload_models()\n",
        "\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import io\n",
        "import re"
      ],
      "id": "2PCbzU8p-hkB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "57b06e2a"
      },
      "outputs": [],
      "source": [
        "# @title üê∂ T4 usage is best  { vertical-output: true, form-width: \"33%\", display-mode: \"form\" }\n",
        "inputscript = \"\" # @param {type:\"string\"}\n",
        "language = \"en\" # @param [\"de\", \"en\", \"es\", \"fr\", \"hi\", \"it\", \"ja\", \"ko\", \"pl\", \"pt\", \"ru\", \"tr\", \"zh\"] {allow-input: true}\n",
        "# @markdown I recommend Voice 3 in English\n",
        "voice = 3 # @param {type:\"slider\", min:0, max:9, step:1}\n",
        "# @markdown *Woooof!*\\\n",
        "# @markdown Low Temperature=üê¢\\\n",
        "# @markdown High Temperature=ü§™\n",
        "GEN_TEMP = 0.8 # @param {type:\"slider\", min:0.4, max:1.1, step:0.001}\n",
        "WAFFLE = 0.075 # @param {type:\"slider\", min:0.02, max:0.1, step:0.001}\n",
        "\n",
        "# Ensure voice is within the valid range (0-9)\n",
        "if voice < 0 or voice > 9:\n",
        "    raise ValueError(\"Voice must be an integer between 0 and 9\")\n",
        "\n",
        "script_template = \"\"\"\n",
        "{inputscript}\n",
        "\"\"\".replace(\"\\n\", \" \").strip()\n",
        "\n",
        "# Replace the {inputscript} placeholder with the actual user input\n",
        "script = script_template.format(inputscript=inputscript)\n",
        "\n",
        "#NLTK preprocessing FIGURE OUT THE [] custom pattern THING LATER https://www.nltk.org/howto/tokenize.html\n",
        "custom_pattern = r'(?<!\\[.*?)(?<!\\])\\s*[.!?](?=\\s+|$)'\n",
        "sentences = nltk.sent_tokenize(script)\n",
        "\n",
        "# Construct the SPEAKER string\n",
        "SPEAKER = f\"v2/{language}_speaker_{voice}\"\n",
        "\n",
        "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
        "\n",
        "# Count the number of characters in the user input\n",
        "num_characters = len(inputscript)\n",
        "# Waffle Devil Fudge\n",
        "waffle_fudge = WAFFLE * 666\n",
        "# Calculate the result in minutes\n",
        "result_in_minutes = round(waffle_fudge * num_characters * 0.3198 / 60)\n",
        "print(f\"\\033[1m\\033[38;5;208mUsing T4 this will take approx {result_in_minutes} minutes\\033[0m\")\n",
        "\n",
        "#WOOF\n",
        "pieces = []\n",
        "for sentence in sentences:\n",
        "    semantic_tokens = generate_text_semantic(\n",
        "        sentence,\n",
        "        history_prompt=SPEAKER,\n",
        "        temp=GEN_TEMP,\n",
        "        min_eos_p=WAFFLE,  # this controls how likely the generation is to end\n",
        "    )\n",
        "\n",
        "    audio_array = semantic_to_waveform(semantic_tokens, history_prompt=SPEAKER,)\n",
        "    pieces += [audio_array, silence.copy()]\n",
        "\n",
        "Audio(np.concatenate(pieces), rate=SAMPLE_RATE, autoplay=True)\n",
        "\n",
        "\n"
      ],
      "id": "57b06e2a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "h5uttPthk0hq",
        "cellView": "form",
        "outputId": "ba40ce6f-4454-4fee-96c9-f528c90d1cbb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3d576a5-1fd9-49b7-9211-bea137a67262\", \"audio.wav\", 68747578)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title ‚áì Download\n",
        "from google.colab import files\n",
        "\n",
        "output_buffer = io.BytesIO()\n",
        "wavfile.write(output_buffer, SAMPLE_RATE, np.concatenate(pieces))\n",
        "\n",
        "output_buffer.seek(0)\n",
        "output_data = output_buffer.read()\n",
        "with open('audio.wav', 'wb') as f:\n",
        "    f.write(output_data)\n",
        "\n",
        "files.download('audio.wav')"
      ],
      "id": "h5uttPthk0hq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lWSOHL69rysl"
      },
      "outputs": [],
      "source": [
        "# @title üìù Each Line of Text\n",
        "# @markdown Maybe each line can be fed into image generation?\n",
        "# Print each sentence on a new line\n",
        "for sentence in sentences:\n",
        "    print(sentence)"
      ],
      "id": "lWSOHL69rysl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C0zQXzQTA7SI"
      },
      "outputs": [],
      "source": [
        "# @title üöß Need to figure out how to unload the Bark model from system RAM\n",
        "import tensorflow as tf\n",
        "\n",
        "# Clear GPU memory\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "id": "C0zQXzQTA7SI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DFzLKGDy5uN",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üß† Install and use Speechbrain for audio enhancement (WILL CRASH UNLESS RUNTIME RESTARTED)\n",
        "\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/templates/enhancement/\n",
        "\n",
        "!pip install speechbrain\n",
        "import speechbrain as sb\n",
        "\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import SpectralMaskEnhancement\n",
        "\n",
        "enhance_model = SpectralMaskEnhancement.from_hparams(\n",
        "    source=\"speechbrain/metricgan-plus-voicebank\",\n",
        "    savedir=\"pretrained_models/metricgan-plus-voicebank\",\n",
        ")\n",
        "\n",
        "# Load and add fake batch dimension\n",
        "noisy = enhance_model.load_audio(\n",
        "    \"/content/woof/audio.wav\"\n",
        ").unsqueeze(0)\n",
        "\n",
        "# Add relative length tensor\n",
        "enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.]))\n",
        "\n",
        "# Saving enhanced signal on disk\n",
        "torchaudio.save('/content/woof/enhanced_audio.wav', enhanced.cpu(), 16000)\n",
        "\n"
      ],
      "id": "_DFzLKGDy5uN"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qFZHPy6b0P6X",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "aafd88d0-8a6e-4e55-a008-e87e3218ed78"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fc3e82dd-c068-4ef2-8802-5591695a607b\", \"enhanced_audio.wav\", 22915898)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title ‚áì Download\n",
        "from IPython.display import Audio\n",
        "\n",
        "# Path to the audio file\n",
        "audio_file_path = '/content/woof/enhanced_audio.wav'\n",
        "\n",
        "# Display the audio player\n",
        "Audio(audio_file_path, rate=16000, autoplay=True)\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/woof/enhanced_audio.wav')"
      ],
      "id": "qFZHPy6b0P6X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FLFqCpQvaDj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üì∫ WebM\n",
        "!pip install ffmpeg\n",
        "!ffmpeg -i /content/woof/enhanced_audio.wav -vf \"scale=300:100,setsar=1:1\" -c:v libvpx -b:v 1M -c:a libvorbis /content/woof/enhanced_audio.webm\n",
        "files.download('/content/woof/enhanced_audio.webm')\n"
      ],
      "id": "1FLFqCpQvaDj"
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üõë Delete and Disconnect\n",
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-tV-Wc7BeBBK"
      },
      "id": "-tV-Wc7BeBBK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03a16c1b"
      },
      "source": [
        "# Dialogue (NOT DONE YET)"
      ],
      "id": "03a16c1b"
    },
    {
      "cell_type": "code",
      "source": [
        "Figure out a smarter way of doing input"
      ],
      "metadata": {
        "id": "08V71lnwf7rc"
      },
      "id": "08V71lnwf7rc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5238b297",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üí¨ UNFINISHED\n",
        "name1 = \"Samantha\" # @param {type:\"string\"}\n",
        "language1 = \"en\" # @param [\"de\", \"en\", \"es\", \"fr\", \"hi\", \"it\", \"ja\", \"ko\", \"pl\", \"pt\", \"ru\", \"tr\", \"zh\"] {allow-input: true}\n",
        "voice1 = 9 # @param {type:\"slider\", min:0, max:9, step:1}\n",
        "# @markdown\n",
        "name2 = \"John\" # @param {type:\"string\"}\n",
        "language2 = \"en\" # @param [\"de\", \"en\", \"es\", \"fr\", \"hi\", \"it\", \"ja\", \"ko\", \"pl\", \"pt\", \"ru\", \"tr\", \"zh\"] {allow-input: true}\n",
        "voice2 = 2 # @param {type:\"slider\", min:0, max:9, step:1}\n",
        "\n",
        "speaker_lookup = {\"Samantha\": \"v2/en_speaker_9\", \"John\": \"v2/en_speaker_2\"}\n",
        "# @markdown Write dialogue?\n",
        "inputscript = \"\"\" Samantha: Hey, have you heard about this new text-to-audio model called \"Bark\"?  John: No, I haven't. What's so special about it?  Samantha: Well, apparently it's the most realistic and natural-sounding text-to-audio model out there right now. People are saying it sounds just like a real person speaking.  John: Wow, that sounds amazing. How does it work?  Samantha: I think it uses advanced machine learning algorithms to analyze and understand the nuances of human speech, and then replicates those nuances in its own speech output.  John: That's pretty impressive. Do you think it could be used for things like audiobooks or podcasts?  Samantha: Definitely! In fact, I heard that some publishers are already starting to use Bark to create audiobooks. And I bet it would be great for podcasts too.  John: I can imagine. It would be like having your own personal voiceover artist.  Samantha: Exactly! I think Bark is going to be a game-changer in the world of text-to-audio technology.\"\"\" # @param {type:\"raw\"}\n",
        "# @markdown *Woooof!*\n",
        "GEN_TEMP = 0.8 # @param {type:\"slider\", min:0.4, max:1.1, step:0.001}\n",
        "WAFFLE = 0.075 # @param {type:\"slider\", min:0.02, max:0.1, step:0.001}\n",
        "\n",
        "# Script generated by chat GPT\n",
        "script = \"\"\"\n",
        "Samantha: Hey, have you heard about this new text-to-audio model called \"Bark\"?\n",
        "\n",
        "John: No, I haven't. What's so special about it?\n",
        "\n",
        "Samantha: Well, apparently it's the most realistic and natural-sounding text-to-audio model out there right now. People are saying it sounds just like a real person speaking.\n",
        "\n",
        "John: Wow, that sounds amazing. How does it work?\n",
        "\n",
        "Samantha: I think it uses advanced machine learning algorithms to analyze and understand the nuances of human speech, and then replicates those nuances in its own speech output.\n",
        "\n",
        "John: That's pretty impressive. Do you think it could be used for things like audiobooks or podcasts?\n",
        "\n",
        "Samantha: Definitely! In fact, I heard that some publishers are already starting to use Bark to create audiobooks. And I bet it would be great for podcasts too.\n",
        "\n",
        "John: I can imagine. It would be like having your own personal voiceover artist.\n",
        "\n",
        "Samantha: Exactly! I think Bark is going to be a game-changer in the world of text-to-audio technology.\"\"\"\n",
        "script = script.strip().split(\"\\n\")\n",
        "script = [s.strip() for s in script if s]\n",
        "script"
      ],
      "id": "5238b297"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "203e5081"
      },
      "outputs": [],
      "source": [
        "pieces = []\n",
        "silence = np.zeros(int(0.5*SAMPLE_RATE))\n",
        "for line in script:\n",
        "    speaker, text = line.split(\": \")\n",
        "    audio_array = generate_audio(text, history_prompt=speaker_lookup[speaker], )\n",
        "    pieces += [audio_array, silence.copy()]"
      ],
      "id": "203e5081"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27a56842"
      },
      "outputs": [],
      "source": [
        "Audio(np.concatenate(pieces), rate=SAMPLE_RATE)"
      ],
      "id": "27a56842"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "03a16c1b"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}